{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efht7F0wV4wo"
      },
      "source": [
        "# Master 2023 - Degradation of Norwegian Wind Farms\n",
        "\n",
        "To run this program, all the files in Data/Værdata at OneDrive need to be uploaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IHsDFrD0v3Z"
      },
      "outputs": [],
      "source": [
        "#Installing required libraries\n",
        "!pip install windpowerlib\n",
        "!pip install windrose\n",
        "!pip install pmdarima\n",
        "!pip install xarray==0.21.1\n",
        "!pip install geopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuD9kTpm00Yb"
      },
      "outputs": [],
      "source": [
        "# Libraries for working with multidimensional arrays\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "# Libraries for plotting and visualising data\n",
        "import matplotlib.path as mpath\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import altair as alt\n",
        "from windrose import WindroseAxes\n",
        "import seaborn as sns\n",
        "\n",
        "from windpowerlib import ModelChain, WindTurbine, create_power_curve\n",
        "from windpowerlib import data as wt\n",
        "from windpowerlib.power_output import power_coefficient_curve\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.stats.diagnostic as smd\n",
        "from scipy.stats import shapiro\n",
        "from scipy.stats import mannwhitneyu\n",
        "from statsmodels.stats.diagnostic import linear_rainbow,linear_harvey_collier,het_breuschpagan\n",
        "\n",
        "import pmdarima as pm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "import statsmodels.graphics.tsaplots as tsa\n",
        "from scipy import stats\n",
        "\n",
        "import geopy.distance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT-EvTA5KARd"
      },
      "source": [
        "# Functions for treating production data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "power_coeff=pd.read_csv(\"https://pvexpect.com/Green_hydrogen/power_coefficient_2.csv\", delimiter=\";\")\n",
        "\n",
        "def create_production_dataframe(chosen_windfarms):\n",
        "\n",
        "  # we start by loading the wind energy production data from an Excel file.\n",
        "  wind_energy = pd.read_excel(\"NVE_prod_2002_2023.xlsx\")\n",
        "\n",
        "  #@title Data structuring of wind production data\n",
        "\n",
        "  #We skips the first rows as they do not contain time series data\n",
        "  wind_energy = wind_energy[2:]\n",
        "  #Rename the 'kraftverknavn' column to 'timestamp' for clarity.\n",
        "  wind_energy.rename(columns={'kraftverknavn': 'time'}, inplace=True)\n",
        "\n",
        "  #Convert the 'timestamp' column to datetime format.\n",
        "  wind_energy['time'] = pd.to_datetime(wind_energy['time'])\n",
        "\n",
        "  #Create a new 'year' column by extracting the year from the 'timestamp' column.\n",
        "  wind_energy['year'] = wind_energy.time.dt.year\n",
        "\n",
        "  #Set the 'timestamp' column as the index for time-based analysis.\n",
        "  wind_energy.set_index(\"time\", inplace=True)\n",
        "\n",
        "  # Display the first few rows of the structured data for inspection.\n",
        "  wind_energy.head(100)\n",
        "\n",
        "  #Choosing production data for choosen wind farms and saving into separate file\n",
        "  wind_energy_chosen =wind_energy[chosen_windfarms]\n",
        "\n",
        "  wind_energy_chosen.to_csv('nve_prod_chosen_2023.csv', index=True)\n",
        "\n",
        "\n",
        "# Grouping hourly data into monthly data, by summing. Counting is also an option\n",
        "def period_resampled_data(df,on_column,period = 'M', hours = None):\n",
        "  if hours is None:\n",
        "    df_monthly = df[str(on_column)].resample(period).agg(['sum'])\n",
        "    df_monthly.columns = [\"Production\"]\n",
        "  else:\n",
        "    df_monthly = df[str(on_column)].resample(period).agg(['sum', 'count'])\n",
        "    df_monthly.columns = [\"Production\", \"Hours\"]\n",
        "  return df_monthly\n",
        "\n",
        "#Finding first valid production hour and the hour one year later. This latter is used as first production hour.\n",
        "def first_valid_hour(df,column = None):\n",
        "  df = pd.DataFrame(df)\n",
        "  if column is None:\n",
        "    column = df.columns[0]\n",
        "\n",
        "  #Finding first production hour\n",
        "  index_of_first_valid_value = df[str(column)].first_valid_index()\n",
        "  one_year = str(pd.to_datetime(index_of_first_valid_value) + pd.Timedelta(365, unit=\"d\"))\n",
        "\n",
        "  return index_of_first_valid_value, one_year\n",
        "\n",
        "#Creating production index\n",
        "def create_production_index(df_measured, df_simulated):\n",
        "  production_index = df_measured.div(df_simulated)\n",
        "  production_index.columns = ['Production Index']\n",
        "  return production_index"
      ],
      "metadata": {
        "id": "cLCMcgxot9Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAR-7wrCdPfd"
      },
      "outputs": [],
      "source": [
        "#Selecting n years of the production index dataframe and returning this\n",
        "\n",
        "def select_period(df,num_years):\n",
        "  _,one_year = first_valid_hour(df)\n",
        "\n",
        "  end_date = pd.to_datetime(one_year) + pd.Timedelta(365 * num_years, unit=\"d\")\n",
        "\n",
        "  #greater than the start date and smaller than the end date\n",
        "  selected_df = df[one_year:end_date]\n",
        "\n",
        "  return selected_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construction of weather data"
      ],
      "metadata": {
        "id": "rpxdq2WUs-cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combining climate data set into one file\n",
        "def combine_nc_dataset(name):\n",
        "  full = xr.open_mfdataset(name + '_*_*.nc',combine = 'nested', concat_dim=\"time\")\n",
        "  full.to_netcdf(name + '_combined.nc')\n",
        "\n",
        "#Modified version of Jesper Frausig´s code\n",
        "#Construct columns from the downloaded parameters in the climate data.\n",
        "\n",
        "def construct_columns(nc_name, ds):\n",
        "  da = ds[nc_name]\n",
        "  weights = np.cos(np.deg2rad(da.latitude))\n",
        "  weights.name = \"weights\"\n",
        "  t2m_C_weighted = da.weighted(weights)\n",
        "\n",
        "  data_values=t2m_C_weighted.mean([\"longitude\", \"latitude\"])\n",
        "  df = pd.DataFrame({\"date\": data_values.time, \"value\": data_values})\n",
        "  df['timestamp']=df.date\n",
        "  df.set_index('timestamp', inplace=True)\n",
        "  df.drop(\"date\", axis=1, inplace=True)\n",
        "  nc_variable=df\n",
        "  return nc_variable\n",
        "\n",
        "#Modified version of Jesper Frausig´s code\n",
        "#Calculating the direction of the wind speed\n",
        "def create_wind_direction_df(v10, u10):\n",
        "  angle = np.arctan2(v10.value,u10.value)\n",
        "  df_wind_direction=pd.DataFrame()\n",
        "  df_wind_direction['wdir']= angle * (180/np.pi) + 180\n",
        "  return df_wind_direction\n",
        "\n",
        "#Creating a wind rose plot from wind speeds and direction\n",
        "def create_windrose(wind):\n",
        "  ax = WindroseAxes.from_ax()\n",
        "  ax.bar(wind.wdir.to_numpy(), wind.wind_speed.to_numpy(), normed=True, opening=0.8, edgecolor='white')\n",
        "  ax.set_legend()\n",
        "\n",
        "#Constructing  a dataframe containg wind_speed, temperature, pressure and roughness_length. The time are used as index.\n",
        "def construct_weather_data(u10, v10,t2m, sp,fsr):\n",
        "  weather_data=pd.DataFrame()\n",
        "  weather_data['wind_speed']=((u10.value)**2+(v10.value)**2)**(0.5)\n",
        "  weather_data['temperature'] = t2m\n",
        "  weather_data['pressure'] = sp\n",
        "  weather_data['roughness_length'] = fsr\n",
        "\n",
        "  weather_data['timestamp']=weather_data.index\n",
        "  return weather_data\n",
        "\n",
        "#Creating a dataframe suitable for windpowerlib. Height are adjusted for wind speed and temperature\n",
        "def construct_weather_windpowerlib(weather_data):\n",
        "\n",
        "  df_weather_windpowerlib = pd.DataFrame(weather_data[['wind_speed','temperature','pressure','roughness_length']])\n",
        "  header =[['wind_speed','temperature','pressure','roughness_length'],[100,2,0, 0]]\n",
        "  df_weather_windpowerlib.columns = header\n",
        "  return df_weather_windpowerlib"
      ],
      "metadata": {
        "id": "fJ-QhUMcs9vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Windpowerlib functions"
      ],
      "metadata": {
        "id": "1-5XLwvGskaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a turbine object. If the turbine type exist in windpowerlib, it uses that object.\n",
        "#If not, it creats a new object using a defined function below.\n",
        "def create_turbine_object(vindpark):\n",
        "  df = wt.get_turbine_types(print_out=False)\n",
        "\n",
        "  if df[df[\"turbine_type\"].str.contains(vindpark['Model_2'])]['turbine_type'].any():\n",
        "    my_turbine= WindTurbine(hub_height=vindpark[\"hub_height\"],turbine_type=vindpark['Model_2'])\n",
        "\n",
        "  else:\n",
        "    my_turbine = create_new_turbine_object(vindpark)\n",
        "\n",
        "  return my_turbine"
      ],
      "metadata": {
        "id": "DNN8L7EzsowF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a new turbine objects using Windpowerlib if the turbine does not already exist in the library.\n",
        "#Powercurve are created using a different defined punction\n",
        "def create_new_turbine_object(Vindpark):\n",
        "  new_turbine = {\n",
        "      \"turbine_type\": Vindpark['Model_2'],\n",
        "      \"nominal_power\": (Vindpark['Maksimal effekt'] *10**6),  # in W\n",
        "      \"hub_height\": Vindpark['hub_height'],  # in m\n",
        "      \"power_curve\": make_power_curve(external_power_curves['wind_speed'],  external_power_curves[Vindpark['Model_2']]),\n",
        "  }\n",
        "  new_turbine = WindTurbine(**new_turbine)\n",
        "\n",
        "  return new_turbine"
      ],
      "metadata": {
        "id": "xythgQKWso9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating power curves that does not exist in windpowerlib from external power curves\n",
        "def make_power_curve(wind_speed, power):\n",
        "  power_curve = create_power_curve(wind_speed = wind_speed, power = power)\n",
        "\n",
        "  return power_curve"
      ],
      "metadata": {
        "id": "6cmXcJ48tfPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJHRFqYqKjAx"
      },
      "outputs": [],
      "source": [
        "#Simulating a tubine and using this tubine to simulated the rest of the farm\n",
        "def windpowerlib_simulation(Vindpark,Vindpark_navn, weather_data):\n",
        "    my_turbine = create_turbine_object(Vindpark)\n",
        "\n",
        "    mc_my_turbine = ModelChain(my_turbine, wind_speed_model='logarithmic', hub_height=portfolio[Vindpark_navn]['hub_height'], density_correction=True).run_model(weather_data)\n",
        "    my_turbine.power_output = mc_my_turbine.power_output\n",
        "    simulated_data = wind_farm_simulated_power_output(my_turbine, Vindpark)\n",
        "\n",
        "\n",
        "    return simulated_data, my_turbine"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modified version of Jesper Frausig´s code\n",
        "def wind_farm_simulated_power_output(my_turbine, vindpark):\n",
        "\n",
        "  # Extract power output data from the turbine model and store it in 'simulated_data'\n",
        "  simulated_data=my_turbine.power_output\n",
        "\n",
        "  # Localize the timezone of the simulated data and scale it\n",
        "  # (by converting it to MW and adjusting for the number of operational turbines)\n",
        "  simulated_data=simulated_data.tz_localize(None)\n",
        "  simulated_data=simulated_data*(10**-6)*vindpark['Antall operative turbiner']\n",
        "\n",
        "  # Convert simulated data to DataFrame for further manipulations\n",
        "  simulated_data=pd.DataFrame(simulated_data)\n",
        "  # Display the total sum of the simulated data for quick inspection\n",
        "  print(simulated_data.sum())\n",
        "\n",
        "  return simulated_data"
      ],
      "metadata": {
        "id": "Ay7NsdVtsoWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for plotting power output\n",
        "def plot_power_output(my_turbine, vindpark):\n",
        "  my_turbine.power_output.plot(legend=True, label= vindpark['Model_2'])\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Power in MW')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "3Th57Incs4Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting power coefficient curve\n",
        "#This code is a modefied version of the code from Windpowerlib: https://windpowerlib.readthedocs.io/en/stable/modelchain_example_notebook.html\n",
        "def plot_power_coefficient_curve(my_turbine, vindpark):\n",
        "  if my_turbine.power_coefficient_curve is not None:\n",
        "          my_turbine.power_coefficient_curve.plot(\n",
        "              x='wind_speed', y='value', style='*',\n",
        "              title= vindpark['Model_2'] +' power coefficient curve')\n",
        "          plt.xlabel('Wind speed in m/s')\n",
        "          plt.ylabel('Power Coefficient, Cp')\n",
        "          plt.show()\n",
        "\n",
        "\n",
        "#Plotting power curve\n",
        "def plot_power_curve(my_turbine, vindpark):\n",
        "  if my_turbine.power_curve is not None:\n",
        "          power_curve = my_turbine.power_curve.plot(x='wind_speed', y='value', style='*',\n",
        "                                      title= vindpark['Model_2'] +' power curve')\n",
        "          plt.xlabel('Wind speed in m/s')\n",
        "          plt.ylabel('Power in MW')\n",
        "          plt.show()"
      ],
      "metadata": {
        "id": "ZKGX2_rrs31Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88mcn0QZvZIm"
      },
      "outputs": [],
      "source": [
        "#Making an aggregated Power curve for the whole wind farm\n",
        "\n",
        "def windfarm_powercurve(my_turbine, Vindpark):\n",
        "  #Creating  powercurves\n",
        "  power_curve_wind_farm = my_turbine.power_curve\n",
        "  power_curve_wind_farm['value'] = power_curve_wind_farm['value'] * Vindpark['Antall operative turbiner']*(10**-6)\n",
        "  return power_curve_wind_farm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distances\n",
        "\n",
        "Functions to calculate distances between the wind farm and coordinate given in the climate dataset are in this section."
      ],
      "metadata": {
        "id": "_ZxYGIpxsTSj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd3oJ__hWFbh"
      },
      "outputs": [],
      "source": [
        "#Getting coordinate to weather data\n",
        "def get_weather_coords(ds):\n",
        "  latitude = ds['latitude'].values[0]\n",
        "  longitude = ds['longitude'].values[0]\n",
        "  weather_coordinate = (latitude,longitude)\n",
        "  return weather_coordinate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSKyt0H4DEvW"
      },
      "outputs": [],
      "source": [
        "#calculating distance between weather coordinate and wind farm coordinate\n",
        "def get_df_distance(ds,Vindpark_navn):\n",
        "  weather_coord = get_weather_coords(ds)\n",
        "\n",
        "  latitude_windfarm = portfolio[Vindpark_navn]['Latitude']\n",
        "  longitude_windfarm = portfolio[Vindpark_navn]['Longitude']\n",
        "\n",
        "  wind_farm_coord = (latitude_windfarm, longitude_windfarm)\n",
        "\n",
        "  distance_km = geopy.distance.geodesic(weather_coord, wind_farm_coord).km\n",
        "\n",
        "  df_distance = pd.DataFrame({'Wind_farm': Vindpark_navn,\n",
        "                              'Weather_coordinate': str(weather_coord),\n",
        "                              'Windfarm_coordinate': str(wind_farm_coord),\n",
        "                              'Distance': distance_km}, index = [0])\n",
        "  return df_distance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning & detection of partial downtime\n",
        "\n",
        "The functions in this section are used to identify partial downtime.\n"
      ],
      "metadata": {
        "id": "e4D_xHTNjbsX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGy4ZUuz7cIw"
      },
      "outputs": [],
      "source": [
        "#Adjusting data points that are larger than the maximum rated power to maximum rated power.\n",
        "#Data points below zero are adjusted to zero and missing points are set to the average of the successor and predecessor\n",
        "def data_cleaning(data_set, Vindpark_navn, Vindpark):\n",
        "\n",
        "  data_set.loc[data_set[Vindpark_navn] < 0, Vindpark_navn] = 0\n",
        "\n",
        "  data_set.loc[data_set[Vindpark_navn] > Vindpark['Maksimal effekt'], Vindpark_navn] = Vindpark['Maksimal effekt']\n",
        "  data_set.loc[data_set[Vindpark_navn].isnull(), Vindpark_navn] = (data_set[Vindpark_navn].fillna(method='ffill')+data_set[Vindpark_navn].fillna(method='bfill'))/2\n",
        "  return data_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut2gdE0GWtnH"
      },
      "outputs": [],
      "source": [
        "#Downtime is defined as all points that have consequetive 3 hours of zero production when inside production interval (5-25 m/s)\n",
        "\n",
        "def downtime(df, Vindpark_navn):\n",
        "  #Finding all entries that are NOT equal to zero.\n",
        "  mask_d = df[Vindpark_navn].ne(0)\n",
        "  #Finding cumulative sum of using the masked function\n",
        "  cumsum_d = df.groupby(mask_d.cumsum())[Vindpark_navn].transform('size')\n",
        "  #Datapoints that are within operational wind speed and that have three consequetive zeros .\n",
        "  df_downtime_zero_production = df.loc[((df['wind_speed'] > 5) & (df['wind_speed'] < 25)) & (cumsum_d.gt(3).mask(mask_d, False))]\n",
        "  #Returning this downtime.\n",
        "  return df_downtime_zero_production"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCBjOQvmQX0n"
      },
      "outputs": [],
      "source": [
        "#Creating a power curve 80% of the size a the original. Furthermore it is shifted to the right making only abnormal points lie beneath the curve.\n",
        "def create_80_power_curve(power_curve_wind_farm):\n",
        "  new_power_curve = power_curve_wind_farm.copy()\n",
        "  new_power_curve['wind_speed'] = new_power_curve['wind_speed'] +5\n",
        "  new_power_curve['value'] = new_power_curve['value'] *0.8\n",
        "  return new_power_curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2h45cPJ_250"
      },
      "outputs": [],
      "source": [
        "#This function identifies production points that lie beneath a power curve\n",
        "def find_points_under_powercurve(scatterplot, curve, vindpark_navn):\n",
        "  x_curve = curve['wind_speed']\n",
        "  y_curve = curve['value']\n",
        "  # Filter points that are below the curve\n",
        "\n",
        "  df_under_pc = pd.DataFrame(columns=['wind_speed', 'value'])\n",
        "\n",
        "  for index, row in scatterplot.iterrows():\n",
        "      if row[vindpark_navn] < np.interp(row['wind_speed'], x_curve, y_curve):\n",
        "        new_row = pd.DataFrame({'wind_speed':row['wind_speed'], 'value': row[vindpark_navn]}, index = [index])\n",
        "        df_under_pc = pd.concat([df_under_pc, new_row])\n",
        "\n",
        "  return df_under_pc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXgRnpGDzGOr"
      },
      "outputs": [],
      "source": [
        "def cumulative_effect_wind_farm(Vindpark):\n",
        "  #Adjusting powercurve to the entire wind farm\n",
        "  num_turbines = Vindpark['Antall operative turbiner']\n",
        "  df_cumulative_effect = pd.DataFrame({ 'Num_windturbines' : range(1, int(num_turbines) +1 ,1)})\n",
        "  effect_per_turbine = Vindpark['Maksimal effekt']/Vindpark['Antall operative turbiner']\n",
        "  df_cumulative_effect['Cumulative_effect'] = df_cumulative_effect.Num_windturbines * effect_per_turbine\n",
        "  return df_cumulative_effect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDuh498qDUjI"
      },
      "outputs": [],
      "source": [
        "#Finding points that are located near a effect line\n",
        "def find_neigbour_points(df_cumulative_effect,df_scatter):\n",
        "  horizontal_line_y = df_cumulative_effect['Cumulative_effect']\n",
        "  distance_threshold = 0.05\n",
        "\n",
        "  df_neigbours = pd.DataFrame(columns = ['wind_speed', 'value', 'effect'])\n",
        "  for line in horizontal_line_y:\n",
        "    for index, row in df_scatter.iterrows():\n",
        "        if abs(row['value'] - line) < distance_threshold:\n",
        "          new_row = pd.DataFrame({'wind_speed':row['wind_speed'], 'value': row['value'],'effect': line}, index = [index])\n",
        "          df_neigbours = pd.concat([df_neigbours, new_row])\n",
        "\n",
        "  return df_neigbours\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyC0HkAhmlLE"
      },
      "outputs": [],
      "source": [
        "#Removing partial downtime from the production data set\n",
        "def remove_downtime_points(df_production, df_downtime):\n",
        "  df_production = df_production.drop(df_downtime.index)\n",
        "  return df_production"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics, residuals and statistic tests\n",
        "\n",
        "Metrics and residuals are calculated to the different models to chose the quality of the models as well as chosing the best model."
      ],
      "metadata": {
        "id": "HroGpCh3m7H-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB_Z4S4UEOrg"
      },
      "outputs": [],
      "source": [
        "#Creating three metrics to a wind farm using y_test and the predicted y\n",
        "def get_metrics(vindpark_navn, y_test,y_pred):\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "  df_metrics = pd.DataFrame({'Wind Farm': vindpark_navn, 'R2': r2, 'MSE': mse, 'MAE': mae}, index = [vindpark_navn])\n",
        "\n",
        "  return df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKRZOgnQFdYI"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Creating different statistical tests to test the linear assumptions\n",
        "def regression_assumptions(vindpark_navn,X_train, X_test,y_train, y_test, y_pred, df):\n",
        "  sns.pairplot(df, x_vars='Time', y_vars='Production Index', height=7, aspect=0.7)\n",
        "  residuals = pd.DataFrame(y_test - y_pred)\n",
        "\n",
        "  lr_model = OLS(y_train, X_train).fit()\n",
        "  rainbow_test = linear_rainbow(lr_model, frac = 0.5)\n",
        "  ljungbox = smd.acorr_ljungbox(residuals,return_df=True)\n",
        "  min_ljung_pvalue = min(ljungbox.lb_pvalue)\n",
        "\n",
        "  df_tests = pd.DataFrame({'Ljungbox test': min_ljung_pvalue,'Rainbow test': rainbow_test[1],\n",
        "                           'Shapiro-Wilk test':shapiro(df)[1],'Goldfeld Quandt':smd.het_goldfeldquandt(residuals, X_test)[1]}, index=[vindpark_navn])\n",
        "  return df_tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5u4589KrqyQ"
      },
      "outputs": [],
      "source": [
        "#Calculating mean squared error and mean absolute error to the auto arima model\n",
        "def forecast_metrics_arima(Vindpark_navn, forecast, actual):\n",
        "  mse = np.mean((forecast - actual)**2) # MSE\n",
        "  mae = np.mean(np.abs(forecast - actual))    # MAE\n",
        "\n",
        "  arima_metrics = pd.DataFrame({'MSE': mse, 'MAE': mae}, index = [Vindpark_navn])\n",
        "  return arima_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression models\n",
        "\n",
        "The modeling phase consists of creating the different algorithms used in the modeling as well as"
      ],
      "metadata": {
        "id": "DHf_APGa985u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF2NZWGcCoPB"
      },
      "outputs": [],
      "source": [
        "#Function to sleect type of regression, normal, seasonal or limited normal\n",
        "def methods_regression(simulated_data,valid_energy_prod,Vindpark_navn, type_reg, num_years = 0):\n",
        "  #Translite if-else\n",
        "\n",
        "  if type_reg == \"Month\":\n",
        "      period = 'M'\n",
        "  elif type_reg ==\"Season\":\n",
        "    period = 'W'\n",
        "  else:\n",
        "    period = 'M'\n",
        "\n",
        "  #Grouping simulated and measured production data into a specific period, mostly months.\n",
        "  df_period_simulated = period_resampled_data(simulated_data,'feedin_power_plant',period, hours = None)\n",
        "  df_period_measured = period_resampled_data(valid_energy_prod,Vindpark_navn, period, hours = None)\n",
        "\n",
        "  #Creating a production indec\n",
        "  df_production_index_periodly = create_production_index(df_period_measured, df_period_simulated)\n",
        "\n",
        "  #If true, only first n years of data are used\n",
        "  if num_years != 0:\n",
        "    df_production_index_periodly = select_period(df_production_index_periodly, num_years)\n",
        "\n",
        "  #Models for monthly data\n",
        "  if type_reg =='Month':\n",
        "    #Running the three models\n",
        "    arima_slope, arima_metrics = auto_arima(df_production_index_periodly, Vindpark_navn)\n",
        "    results, lr_metrics, ran_metrics, lr_residuals,ran_residuals = reg_RANSAC(df_production_index_periodly,Vindpark_navn,'Plot')\n",
        "\n",
        "    #Getting slipes\n",
        "    lin_slope = results['Linear_coefficient']\n",
        "    ransac_slope = results['Ransac_coefficient']\n",
        "\n",
        "    #Estimating yearly degradation tto the models\n",
        "    yearly_degradation_lin = 12 * lin_slope\n",
        "    yearly_degradation_ransac = 12 * ransac_slope\n",
        "    yearly_degradation_arima = 12 * arima_slope\n",
        "\n",
        "    #this is sed to create a results df that are returned\n",
        "    results_degrad = pd.DataFrame({'Wind_farm': str(Vindpark_navn),\n",
        "                'Linear_degradation': round(float(yearly_degradation_lin),4),\n",
        "                'Ransac_degradation': round(float(yearly_degradation_ransac),4),\n",
        "                'Arima degradation': round(float(yearly_degradation_arima),4)}, index=[0])\n",
        "\n",
        "    return results_degrad, lr_metrics, ran_metrics,arima_metrics, lr_residuals,ran_residuals\n",
        "\n",
        "  #Models for seasonal regression\n",
        "  elif type_reg == 'Season':\n",
        "    #Finding the specific years of production\n",
        "    unique_years = pd.DataFrame(df_production_index_periodly.index.year).drop_duplicates()['time'].tolist()\n",
        "    df_production_index_periodly['quarters'] = df_production_index_periodly.index.quarter\n",
        "\n",
        "    #Making dataframes containg all four quarters and all years from unique years.\n",
        "    quarters = {'Q1': 1,'Q2': 2,'Q3': 3,'Q4': 4}\n",
        "    df_year_lr = pd.DataFrame(columns = ['Year','Q1','Q2','Q3','Q4' ])\n",
        "    df_year_ran = pd.DataFrame(columns = ['Year','Q1','Q2','Q3','Q4' ])\n",
        "    for year in unique_years:\n",
        "      year_row_lr = pd.DataFrame({'Year': year,\n",
        "                  'Q1': None,\n",
        "                  'Q2': None,\n",
        "                  'Q3': None,\n",
        "                  'Q4': None}, index = [0])\n",
        "\n",
        "      year_row_ran = pd.DataFrame({'Year': year,\n",
        "                  'Q1': None,\n",
        "                  'Q2': None,\n",
        "                  'Q3': None,\n",
        "                  'Q4': None}, index = [0])\n",
        "\n",
        "      #Iterating over each quarter and running regression models\n",
        "      df_new = df_production_index_periodly.iloc[(df_production_index_periodly.index.year == year)]\n",
        "      for quarter in quarters:\n",
        "        df_q = df_new.iloc[df_new['quarters'].values == quarters[quarter]]\n",
        "\n",
        "        if df_q.shape[0] > 10:\n",
        "          results_degrad, lr_metrics, ran_metrics = reg_RANSAC(df_q)\n",
        "          year_row_lr.loc[year_row_lr[quarter].values == None, quarter] = results_degrad['Linear_coefficient']\n",
        "          year_row_ran.loc[year_row_ran[quarter].values == None, quarter] = results_degrad['Ransac_coefficient']\n",
        "\n",
        "      #These are added to the data frame\n",
        "      df_year_lr = pd.concat([df_year_lr,year_row_lr], ignore_index=True)\n",
        "      df_year_ran = pd.concat([df_year_ran, year_row_ran], ignore_index=True)\n",
        "\n",
        "    #The average degradation to each quarter are calculated and return in dataframe format.\n",
        "    df_avg_wind_lr = pd.DataFrame({'Q1': df_year_lr['Q1'].mean(),\n",
        "                                  'Q2': df_year_lr['Q2'].mean(),\n",
        "                                  'Q3': df_year_lr['Q3'].mean(),\n",
        "                                  'Q4': df_year_lr['Q4'].mean()}, index = [Vindpark_navn])\n",
        "    df_avg_wind_ran = pd.DataFrame({'Q1': df_year_ran['Q1'].mean(),\n",
        "                                'Q2': df_year_ran['Q2'].mean(),\n",
        "                                'Q3': df_year_ran['Q3'].mean(),\n",
        "                                'Q4': df_year_ran['Q4'].mean()}, index = [Vindpark_navn])\n",
        "    return df_avg_wind_lr,df_avg_wind_ran, lr_metrics, ran_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRdB1WxOPM3I"
      },
      "outputs": [],
      "source": [
        "#Regression function that conducts normal linear regression and Ransac regression. Returining, metrics, tests, coefficients and plotting the results\n",
        "def reg_RANSAC(df, vindpark_navn = None, regression_plot = None):\n",
        "  #Copying tthe production index data and adding a dummy variable for regression\n",
        "  df = df.copy()\n",
        "  df['Time'] = np.arange(len(df.index))\n",
        "\n",
        "\n",
        "  # Dividing into  target and feature data\n",
        "  X = df.loc[:, ['Time']].values  # features\n",
        "  y = df.loc[:, ['Production Index']].values  # target\n",
        "\n",
        "  #Splitting into training and test set\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0,test_size=0.20, shuffle=False)\n",
        "\n",
        "  #Making parameter grid for grid search\n",
        "  if X_train.shape[0] > 25:\n",
        "    param_grid = {'min_samples': [20,25,30,40],\n",
        "                'residual_threshold':[0.375, 0.5,0.625, 0.75,1.0,1.5,2.0,2.5,3.0]}\n",
        "  else:\n",
        "    param_grid = {'min_samples': [4,6,8,10,12],\n",
        "                'residual_threshold':[0.375, 0.5,0.625, 0.75,1.0,1.5,2.0,2.5,3.0]}\n",
        "\n",
        "  #Fitting and predicting a Linear regression model\n",
        "  lr = LinearRegression()\n",
        "  lr.fit(X_train, y_train)\n",
        "  y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "  #Creating a ransac regression model\n",
        "  ransac = RANSACRegressor(LinearRegression(),\n",
        "                          max_trials = 100,\n",
        "                          loss = 'absolute_error',\n",
        "                          random_state = 0)\n",
        "\n",
        "  #Fitting a grid search\n",
        "  gs = GridSearchCV(estimator=ransac, param_grid = param_grid, n_jobs=-1)\n",
        "  gs.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "  print(\" Results from Grid Search \" )\n",
        "  print(\"\\n The best estimator across ALL searched params:\\n\",gs.best_estimator_)\n",
        "  print(\"\\n The best score across ALL searched params:\\n\",gs.best_score_)\n",
        "  print(\"\\n The best parameters across ALL searched params:\\n\",gs.best_params_)\n",
        "\n",
        "  #Best parameters from gridsearch are used to fit a new ransac model. Prediction are also made\n",
        "  ransac = gs.best_estimator_\n",
        "\n",
        "  ransac.fit(X_train, y_train)\n",
        "  y_pred_ran = ransac.predict(X_test)\n",
        "\n",
        "\n",
        "  #Plotting the results, marking inliers, outliers and regression lines for both models.\n",
        "  if vindpark_navn is not None:\n",
        "    lr_residuals = regression_assumptions(vindpark_navn,X_train,X_test,y_train, y_test, y_pred_lr, df)\n",
        "    ran_residuals = regression_assumptions(vindpark_navn,X_train,X_test, y_train,y_test, y_pred_ran, df)\n",
        "\n",
        "  lr_metrics = get_metrics(vindpark_navn, y_test,y_pred_lr)\n",
        "  ran_metrics = get_metrics(vindpark_navn, y_test,y_pred_ran)\n",
        "\n",
        "  inlier_mask = ransac.inlier_mask_\n",
        "  outlier_mask = np.logical_not(inlier_mask)\n",
        "\n",
        "\n",
        "  #Predict data of estimated models\n",
        "  line_X_test = np.arange(X_test.min(), X_test.max())[:, np.newaxis]\n",
        "  line_y_test = lr.predict(line_X_test)\n",
        "  line_y_ransac_test = ransac.predict(line_X_test)\n",
        "\n",
        "  line_X_train = np.arange(X_train.min(), X_train.max())[:, np.newaxis]\n",
        "  line_y_train = lr.predict(line_X_train)\n",
        "  line_y_ransac_train = ransac.predict(line_X_train)\n",
        "\n",
        "\n",
        "  # Compare estimated coefficients\n",
        "  lr_coef = lr.coef_\n",
        "  ransac_coef = ransac.estimator_.coef_\n",
        "\n",
        "  #plotting results from linear and ransac model. This code is based on the code from: https://scikit-learn.org/stable/auto_examples/linear_model/plot_ransac.html\n",
        "  if regression_plot is not None:\n",
        "    lw = 2\n",
        "    plt.scatter(\n",
        "        X_train[inlier_mask], y_train[inlier_mask], color=\"yellowgreen\", marker=\".\", label=\"Inliers\"\n",
        "    )\n",
        "    plt.scatter(\n",
        "        X_train[outlier_mask], y_train[outlier_mask], color=\"gold\", marker=\".\", label=\"Outliers\"\n",
        "    )\n",
        "\n",
        "    plt.plot(line_X_train, line_y_train, color=\"navy\", linewidth=lw, label=\"Linear regressor\")\n",
        "    plt.plot(\n",
        "        line_X_train,\n",
        "        line_y_ransac_train,\n",
        "        color=\"cornflowerblue\",\n",
        "        linewidth=lw,\n",
        "        label=\"RANSAC regressor\",\n",
        "    )\n",
        "\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Performance Index\")\n",
        "    plt.show()\n",
        "\n",
        "  #Creating a results df for returning coefficients\n",
        "  results  = pd.DataFrame({'Linear_coefficient': round(float(lr_coef),4),\n",
        "                            'Ransac_coefficient': round(float(ransac_coef),4)}, index=[vindpark_navn])\n",
        "  #Returning coefficients\n",
        "  if vindpark_navn is None:\n",
        "    return results, lr_metrics, ran_metrics\n",
        "  else:\n",
        "    return results, lr_metrics, ran_metrics, lr_residuals,ran_residuals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRQs3b_RxhX6"
      },
      "outputs": [],
      "source": [
        "def auto_arima(df, vindpark_navn = None, regression_plot = None):\n",
        "  #copying the production index df\n",
        "  df_Arima = df.copy()\n",
        "  #adding a dummy column from to use for regression\n",
        "  df_Arima['Time'] = np.arange(len(df_Arima.index))\n",
        "\n",
        "  df_Arima['DateTimeIndex']= pd.to_datetime(df_Arima.index)\n",
        "  df_Arima = df_Arima.set_index(keys=['DateTimeIndex'])\n",
        "\n",
        "  # Training data\n",
        "  dataset_len = df_Arima.shape[0]\n",
        "  split_index = round(dataset_len*0.9)\n",
        "  train_set_end_date = df_Arima.index[split_index]\n",
        "\n",
        "  #dividing into training and test set\n",
        "  df_train = df_Arima.loc[df_Arima.index <= train_set_end_date].copy()\n",
        "  df_test = df_Arima.loc[df_Arima.index > train_set_end_date].copy()\n",
        "\n",
        "  #dividing into feature and target value\n",
        "  y_train = pd.DataFrame(df_train['Production Index'])\n",
        "  X_train = pd.DataFrame(df_train['Time'])  # Extract the index column into a DataFrame\n",
        "\n",
        "  y_test = pd.DataFrame(df_test['Production Index'])\n",
        "  X_test = pd.DataFrame(df_test['Time'])\n",
        "\n",
        "  #Modeling using ordinary least squares and plotting different diagnostic plots\n",
        "  model_lr = OLS(y_train, X_train)\n",
        "  results_lr = model_lr.fit()\n",
        "  rainbow_test = linear_rainbow(results_lr)\n",
        "  residuals = pd.DataFrame(results_lr.resid)\n",
        "\n",
        "  residuals_diff_1 = residuals.diff().dropna()\n",
        "  residuals_diff_2 = residuals_diff_1.diff().dropna()\n",
        "   # autocorrelation\n",
        "  sm.graphics.tsa.plot_acf(residuals,alpha=0.05)\n",
        "  plt.show()\n",
        "\n",
        "  sm.graphics.tsa.plot_acf(residuals.diff().dropna(), alpha=0.05)\n",
        "  plt.show()\n",
        "\n",
        "  sm.graphics.tsa.plot_acf(residuals_diff_2, alpha=0.05)\n",
        "  plt.show()\n",
        "\n",
        "  #Plotting decomposed data\n",
        "  components = seasonal_decompose(residuals)\n",
        "  components.plot()\n",
        "\n",
        "\n",
        "  olsr_resid_diff_1_24 = residuals_diff_1.diff(periods=24)\n",
        "\n",
        "   # partial autocorrelation\n",
        "  sm.graphics.tsa.plot_pacf(residuals)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  # Running sarimx auto arima model\n",
        "  sxmodel = pm.auto_arima(y_train, X_train,\n",
        "                            start_p=1, start_q=1,\n",
        "                            test='adf',\n",
        "                            max_p=3, max_q=3, m=12,\n",
        "                            start_P=0, seasonal=True,\n",
        "                            d=None, D=1, trace=True,\n",
        "                            error_action='ignore',\n",
        "                            suppress_warnings=True,\n",
        "                            stepwise=True)\n",
        "\n",
        "  #Plotting diagnostic\n",
        "  sxmodel.plot_diagnostics(figsize=(10,8))\n",
        "  plt.show()\n",
        "  #Plotting results\n",
        "  print(sxmodel.summary())\n",
        "\n",
        "  #Getting time coefficientt\n",
        "  model_dict = sxmodel.to_dict()\n",
        "  coefficient = model_dict['params']['Time']\n",
        "\n",
        "  #Predicting forcast\n",
        "  prediction = sxmodel.predict(n_periods=len(y_test),X = X_test)\n",
        "  prediction = pd.DataFrame(prediction,index = y_test.index,columns=['Prediction'])\n",
        "\n",
        "  #Calculating. arima errors.\n",
        "  arima_metrics = forecast_metrics_arima(vindpark_navn, prediction['Prediction'], y_test['Production Index'])\n",
        "\n",
        "  #plot the predictions for validation set\n",
        "  plt.plot(y_train, label='Train')\n",
        "  plt.plot(y_test, label='Actual')\n",
        "  plt.plot(prediction, label='Prediction')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "\n",
        "  return coefficient, arima_metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting functions\n",
        "\n",
        "Functions in this section are for plotting different data in the analysis."
      ],
      "metadata": {
        "id": "932Fz5xKkCvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function plots the production against wind resources. Additionally, the power curve, a shifted 80% power curve and pre-efined effectlines are plotted. Data points beneath the 80% PC are marked in a green color. Furthermore, those points that are also close to the effectlines are marked in a yellow color. These are considered part of the partial downtime."
      ],
      "metadata": {
        "id": "DpaDl0iUk6nN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fhklAvXSzyS"
      },
      "outputs": [],
      "source": [
        "#Bar chart showing the count of different turbine types selected in this thesis\n",
        "def plot_distribution_turbines(portfolio_data):\n",
        "  chart = alt.Chart(portfolio_data).mark_bar().encode(\n",
        "      x=alt.X('Model_2:O', title='Model name'),\n",
        "      y=alt.Y('Antall:Q', title='Number of turbines'),\n",
        "      color = 'Manufacture_year:O',\n",
        "      order=alt.Order(\"Manufacture_year:O\", sort='ascending'),\n",
        "  ).configure_axis(\n",
        "      labelFontSize=15,\n",
        "      titleFontSize=20).configure_axis(\n",
        "      labelFontSize=13,\n",
        "      titleFontSize=14)\n",
        "  display(chart)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr4jp_dd3UK7"
      },
      "outputs": [],
      "source": [
        "#Plotting bar chart of wind turbine dimensions using Altair\n",
        "def plot_wind_turbine_dimensions(portfolio_data):\n",
        "  chart_hub_height = alt.Chart(portfolio_data).mark_bar().encode(\n",
        "      x=alt.X('Model_2:O',title='Model name'),\n",
        "      y=alt.Y('hub_height:Q',title='Hub height [m]'),\n",
        "      color = 'Manufacture_year:O'\n",
        "  ).properties(\n",
        "      title='Hub height'\n",
        "  )\n",
        "\n",
        "  chart_rotor_diameter = alt.Chart(portfolio_data).mark_bar().encode(\n",
        "      x=alt.X('Model_2:O',title='Model name'),\n",
        "      y=alt.Y('rotordiameter:Q',title='Rotor diameter [m]'),\n",
        "      color = 'Manufacture_year:O').properties(\n",
        "      title='Rotor diameter'\n",
        "  )\n",
        "\n",
        "\n",
        "  chart_generator_performance = alt.Chart(portfolio_data).mark_bar().encode(\n",
        "      x=alt.X('Model_2:O',title='Model name'),\n",
        "      y=alt.Y('Generator_performance:Q',title='Generator performance [MW]'),\n",
        "      color = 'Manufacture_year:O').properties(\n",
        "      title='Generator performance'\n",
        "  )\n",
        "  chart = alt.hconcat(chart_hub_height, chart_rotor_diameter, chart_generator_performance).properties(\n",
        "  ).configure_axis(\n",
        "      labelFontSize=13,\n",
        "      titleFontSize=14)\n",
        "\n",
        "  display(chart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn-ruPpt2i89"
      },
      "outputs": [],
      "source": [
        "#Plottingthe power curve, a shifted 80% power curve and pre-efined effectlines are plotted. Data points beneath the 80% PC are marked in a green color.\n",
        "#Furthermore, those points that are also close to the effectlines are marked in a yellow color.\n",
        "\n",
        "def plot_production_powercurve(Vindpark_navn,df_weather_downtime,df_under_pc,df_neigbours,df_cumulative_effect,power_curve_wind_farm,new_power_curve):\n",
        "  plt.figure()\n",
        "  plt.scatter(df_weather_downtime['wind_speed'], df_weather_downtime[Vindpark_navn], marker='.', alpha=0.7, label = 'Power production')\n",
        "  plt.scatter(df_under_pc['wind_speed'], df_under_pc['value'], color='yellowgreen', label='Filtered Points', marker='.', alpha=0.7)\n",
        "  plt.scatter(df_neigbours['wind_speed'], df_neigbours['value'], color='gold', label='Points Close to Horizontal Line')\n",
        "  plt.hlines(df_cumulative_effect['Cumulative_effect'], xmin = 0, xmax = 25, colors= 'r', label = 'Cumulative effect lines')\n",
        "  plt.plot(power_curve_wind_farm['wind_speed'],power_curve_wind_farm['value'],color= 'navy', label = 'Power curve')\n",
        "  plt.plot(new_power_curve['wind_speed'],new_power_curve['value'],color= 'cornflowerblue', label = 'Power curve (80%)')\n",
        "  plt.title('Production plot')\n",
        "  plt.xlabel('Wind speed [m/s]')\n",
        "  plt.ylabel('Power production [MW]')\n",
        "  plt.legend(loc = 'upper right', bbox_to_anchor=(1.55, 1.0))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below are used to plot a power curve and a power coefficient curve of one turbine in the same plot."
      ],
      "metadata": {
        "id": "GpS7ZMm5lbxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting power curve and power coefficientt curve to a turbien in the same plot\n",
        "def plot_power_and_coeffcient_curve(my_turbine):\n",
        "  if my_turbine.power_coefficient_curve is not None and my_turbine.power_curve is not None:\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    ax1.set_xlabel('Wind speed in m/s')\n",
        "    ax1.set_ylabel('Cp', color='r')\n",
        "    ax1.plot(my_turbine.power_coefficient_curve['wind_speed'], my_turbine.power_coefficient_curve['value'], color= 'r', label = 'Power Coefficient Curve')\n",
        "    ax1.tick_params(axis='y', labelcolor='r')\n",
        "    ax1.legend(loc= 'lower right')\n",
        "\n",
        "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "    ax2.set_ylabel(('Power in MW'), color='b')\n",
        "    ax2.plot(my_turbine.power_curve['wind_speed'], my_turbine.power_curve['value'], color='b', label='Power curve')\n",
        "    ax2.tick_params(axis='y', labelcolor='b')\n",
        "    ax2.legend(loc=0)\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "BAjYhsNh1yTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlucrFbjMV2N"
      },
      "outputs": [],
      "source": [
        "#make_weighted_degradation is used to calculate average degradation and\n",
        "#weighted average estimation to the different regression models used in this thesis.\n",
        "\n",
        "def make_weighted_degradation(df_result, seasons = False):\n",
        "  proportion_effect = pd.DataFrame(index = portfolio_data.index)\n",
        "  proportion_effect['Maksimal effekt'] = portfolio_data['Maksimal effekt']\n",
        "  tot_effect = portfolio_data['Maksimal effekt'].sum()\n",
        "\n",
        "  proportion_effect['Proportion'] = proportion_effect['Maksimal effekt']/tot_effect\n",
        "\n",
        "  selected_wind_farms = proportion_effect.loc[proportion_effect.index.isin(df_result.index)]\n",
        "\n",
        "  if seasons == False:\n",
        "    df_weight = pd.DataFrame()\n",
        "    df_weight['Weighted_Linear_degradation'] = df_result['Linear_degradation'].values * selected_wind_farms['Proportion']\n",
        "    df_weight['Weighted_Ransac_degradation'] = df_result['Ransac_degradation'].values * selected_wind_farms['Proportion']\n",
        "    df_weight['Weighted_Arima_degradation'] = df_result['Arima degradation'].values * selected_wind_farms['Proportion']\n",
        "\n",
        "\n",
        "\n",
        "    lr_weighted_average = df_weight['Weighted_Linear_degradation'].sum()\n",
        "    ran_weighted_average = df_weight['Weighted_Ransac_degradation'].sum()\n",
        "    arima_weighted_average = df_weight['Weighted_Arima_degradation'].sum()\n",
        "\n",
        "    df_results_avg = pd.DataFrame({'Linear Reg Mean': df_result['Linear_degradation'].mean(),\n",
        "                                  'Ransac Reg Mean':df_result['Ransac_degradation'].mean(),\n",
        "                                  'Arima Reg Mean':df_result['Arima degradation'].mean(),\n",
        "                                  'Linear Reg Weighted Avg':lr_weighted_average,\n",
        "                                  'Ransac Reg Weighted Avg': ran_weighted_average,\n",
        "                                  'Arima Reg Weighted Avg': arima_weighted_average}, index = [0])\n",
        "\n",
        "\n",
        "  elif seasons == True:\n",
        "    df_weight = pd.DataFrame()\n",
        "    df_weight['Weighted_Q1_degradation'] = df_result['Q1'].values * selected_wind_farms['Proportion']\n",
        "    df_weight['Weighted_Q2_degradation'] = df_result['Q2'].values * selected_wind_farms['Proportion']\n",
        "    df_weight['Weighted_Q3_degradation'] = df_result['Q3'].values * selected_wind_farms['Proportion']\n",
        "    df_weight['Weighted_Q4_degradation'] = df_result['Q4'].values * selected_wind_farms['Proportion']\n",
        "\n",
        "    q1_weighted_average = df_weight['Weighted_Q1_degradation'].sum()\n",
        "    q2_weighted_average = df_weight['Weighted_Q2_degradation'].sum()\n",
        "    q3_weighted_average = df_weight['Weighted_Q3_degradation'].sum()\n",
        "    q4_weighted_average = df_weight['Weighted_Q4_degradation'].sum()\n",
        "\n",
        "    df_results_avg = pd.DataFrame({'Q1' :results_season_ran['Q1'].mean() ,\n",
        "                          'Q2' :results_season_ran['Q2'].mean() ,\n",
        "                          'Q3' :results_season_ran['Q3'].mean() ,\n",
        "                          'Q4' :results_season_ran['Q4'].mean() },index = ['Average Degradation'])\n",
        "\n",
        "    df_results_weighted_avg = pd.DataFrame({'Q1' :q1_weighted_average ,\n",
        "                          'Q2' :q2_weighted_average ,\n",
        "                          'Q3' :q3_weighted_average ,\n",
        "                          'Q4' :q4_weighted_average },index = ['Weighted Average Degradation'])\n",
        "\n",
        "    df_results_avg = pd.concat([df_results_avg,df_results_weighted_avg])\n",
        "\n",
        "\n",
        "  return df_results_avg, df_weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi8hSy05Q3TW"
      },
      "outputs": [],
      "source": [
        "#Making a combined confidence interval to the final result\n",
        "def mean_confidence_interval(data_1,data_2, confidence=0.95):\n",
        "  n1 = results_without_downtime['Ransac_degradation'].shape[0]\n",
        "  n2 = df_weighted['Weighted_Ransac_degradation'].shape[0]\n",
        "\n",
        "  df = n1 + n2-2\n",
        "\n",
        "  mean_1 = np.mean(data_1)\n",
        "  mean_2 = np.sum(data_2)\n",
        "  total_mean = (0.5 * mean_1 + 0.5 * mean_2)\n",
        "\n",
        "  std_err_1 = scipy.stats.sem(data_1)\n",
        "  std_err_2 = scipy.stats.sem(data_2)\n",
        "\n",
        "  total_std_error = 0.5 * math.sqrt(((std_err_1**2)/n1 + (std_err_2**2))/n2)\n",
        "\n",
        "\n",
        "  pooled_standard_deviation = math.sqrt(\n",
        "                      ((n1 - 1)*std_err_1 * std_err_1 +\n",
        "                     (n2-1)*std_err_2 * std_err_2) /\n",
        "                                  (n1 + n2-2))\n",
        "\n",
        "  interval = total_std_error * scipy.stats.t.ppf((1 + confidence) / 2., df)\n",
        "  return interval\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions for testing for differences\n",
        "\n",
        "The functions beneath are used to test if there is a significant difference between different groups defined in the thesis. A Mannwhitney u-test are used as the groups are of small sample sizes."
      ],
      "metadata": {
        "id": "gYV4MDlnl_TO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkqZsNNa0sKR"
      },
      "outputs": [],
      "source": [
        "#Running one manwhitney u-test. This returns the groups tested together with test-statistic and p-value\n",
        "def mannwhitney_test(groups, reg_type):\n",
        "  group = list(groups.items())\n",
        "  group_1_name = group[0][0]\n",
        "  group_2_name = group[1][0]\n",
        "  group_1_values = group[0][1]\n",
        "  group_2_values = group[1][1]\n",
        "  U1, p = mannwhitneyu(group_1_values,group_2_values , method='auto')\n",
        "\n",
        "  df_mann_whitneyu = pd.DataFrame({'Test_group_1':group_1_name,'Test_group_2':group_2_name,'Test-statistic':U1, 'p-value' : p}, index = [reg_type])\n",
        "\n",
        "  return df_mann_whitneyu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx8gr_-xa4v4"
      },
      "outputs": [],
      "source": [
        "#This functions allow the program to iterate over multiple tests in the same testing category.\n",
        "def run_u_test_case(cases):\n",
        "  reg_type = cases[0]\n",
        "  test_groups = cases[1]\n",
        "  df_test = pd.DataFrame()\n",
        "  for groups in test_groups:\n",
        "\n",
        "    df = mannwhitney_test(groups, reg_type)\n",
        "    df_test = pd.concat([df_test,df])\n",
        "  return df_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1i-3VvEPhBY"
      },
      "source": [
        "## Chosen windfarms\n",
        "\n",
        "Wind farms are chosen in the section below. Wind farm data are cleaned to ensure the correctness of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSAPq5HwJFM-"
      },
      "outputs": [],
      "source": [
        "#Choosing wind farms\n",
        "chosen_windfarm = {'Egersund':'Egersund','Fakken':'Fakken', 'Hamnefjell':'Hamnefjell','Hitra':'Hitra',  'Kjøllefjord':'Kjollefjord', 'Lista':'Lista', 'Raggovidda':'Raggovidda', 'Rye Vind':'ryevind', 'Røyrmyra':'royrmyra','Sandøy':'Sandoy','Skomakerfjellet':'Skomakerfjellet','Tellenes':'Tellenes', 'Valsneset':'Valsneset','Ytre Vikna':'Ytre_Vikna', 'Åsen II':'Asen2'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJbdBlxySpNL"
      },
      "outputs": [],
      "source": [
        "# Read the wind turbine data from a CSV file\n",
        "portfolio_data = pd.read_csv(\"https://pvexpect.com/Vind/Vindturbine_portfolio_2.csv\", delimiter=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMFnPJm6by8V"
      },
      "outputs": [],
      "source": [
        "#Importing external power_curves and power coefficient curves that was not in windpowerlib\n",
        "external_power_curves = pd.read_csv('PowerCurves.csv',delimiter=\";\")\n",
        "\n",
        "external_power_coeffcient_curves = pd.read_csv('Power_coefficient_curves.csv',delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BicI8BLfIJRu"
      },
      "outputs": [],
      "source": [
        "#Selecting data reagarding the chosen wind farms\n",
        "portfolio_data = portfolio_data.loc[portfolio_data['Navn'].isin(chosen_windfarm)]\n",
        "portfolio_data.head(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgPl5vUQeycv"
      },
      "outputs": [],
      "source": [
        "#Adding a new column with the geografic cluster are defined based on price zones.\n",
        "portfolio_data['Geografic_area'] = None\n",
        "portfolio_data.loc[portfolio_data['Elspotområde'] == 'NO 2','Geografic_area'] = 'South_west'\n",
        "portfolio_data.loc[portfolio_data['Elspotområde'] == 'NO 3','Geografic_area'] = 'Mid'\n",
        "portfolio_data.loc[portfolio_data['Elspotområde'] == 'NO 4','Geografic_area'] = 'North'\n",
        "\n",
        "#Added two columns; one with manufacture year and one with rated power of one turbine\n",
        "portfolio_data['Manufacture_year'] = [2014,2002,2004,2004,2004,2005,2011,1989,2004,1997,2015,2014,2005,2005,2004]\n",
        "portfolio_data['Generator_performance'] = [3.4,3,3.45,2.3,2.3,2.3,3,0.225,0.8,0.750,3.3,3.2,2.3,2.3,0.8]\n",
        "\n",
        "#Adding a column classifying newer and older wind turbines\n",
        "portfolio_data['Age_groups'] = None\n",
        "portfolio_data.loc[portfolio_data['Manufacture_year'] >= 2011,'Age_groups'] = 'New_turbine'\n",
        "portfolio_data.loc[portfolio_data['Manufacture_year'] < 2011,'Age_groups'] = 'Old_turbine'\n",
        "\n",
        "#Extract numerical values from 'Gjennomsnitt navhøyde' column and fill missing values with -1\n",
        "#Modifisert versjon av Jesper Frausig sin kode\n",
        "portfolio_data['hub_height'] = portfolio_data['hub_height'].str.extract('(\\d+)').fillna(-1).astype(int)\n",
        "portfolio_data['rotordiameter'] = portfolio_data['rotordiameter'].str.extract('(\\d+)').fillna(-1).astype(int)\n",
        "#Renaming coordinate colum\n",
        "portfolio_data.rename(columns={\"Lengdegrad\": \"Latitude\", \"Breddegrad\": \"Longitude\"},inplace=True)\n",
        "\n",
        "\n",
        "#Correcting wind farm data that were wrong\n",
        "portfolio_data.loc[portfolio_data['Navn'] == 'Åsen II','Model_2'] = 'E48/800'\n",
        "portfolio_data.loc[portfolio_data['Navn'] == 'Rye Vind','Model_2'] = 'V27/225'\n",
        "\n",
        "portfolio_data.loc[portfolio_data['Navn'] == 'Hitra','Model'] = 'SWT-2.3-82'\n",
        "portfolio_data.loc[portfolio_data['Navn'] == 'Hitra','Model_2'] = 'SWT82/2300'\n",
        "\n",
        "\n",
        "portfolio_data.loc[portfolio_data['Navn'] == 'Sandøy','Model_2'] = 'NM48/750'\n",
        "portfolio_data.loc[portfolio_data['Navn'] == 'Sandøy','hub_height'] = 50\n",
        "portfolio_data.loc[portfolio_data['Navn'] == 'Hitra','hub_height'] = 70\n",
        "\n",
        "portfolio_data.loc[portfolio_data['Navn'] == 'Sandøy','rotordiameter'] = 48.2\n",
        "portfolio_data.loc[portfolio_data['Navn'] == 'Hitra','rotordiameter'] = 82.4\n",
        "\n",
        "\n",
        "\n",
        "#Removed columns that were unnecessary\n",
        "portfolio_data.drop(columns =['Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27',\n",
        "       'Unnamed: 28','Unnamed: 30','Høyde', 'Unnamed: 31','Unnamed: 33','Antall.2',\t'Idriftsatt.2','Turbinprodusent.2',\t'Turbintype.2',\n",
        "                              'Antall.1',\t'Idriftsatt.1','Turbinprodusent.1','Turbintype.1'], inplace = True)\n",
        "\n",
        "#Creating dictionare of the data\n",
        "portfolio = {\n",
        "    turbin: row.to_dict()\n",
        "    for turbin, row in portfolio_data.set_index(\"Navn\").iterrows()\n",
        "}\n",
        "#Setting 'Navn' as index column\n",
        "portfolio_data.set_index('Navn', inplace = True)\n",
        "portfolio_data.index.names = ['Wind_farm']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plottting the count of different wind turbines in used in this thesis\n",
        "plot_distribution_turbines(portfolio_data)"
      ],
      "metadata": {
        "id": "WO15yL4qu1p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the dimensions of the turbines\n",
        "plot_wind_turbine_dimensions(portfolio_data)"
      ],
      "metadata": {
        "id": "RJqGQ-Luu2Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9welxqngdKWc"
      },
      "outputs": [],
      "source": [
        "#Modified version of Jesper Frausig´s code\n",
        "\n",
        "# Define a variable 'norway_counties' and load geojson data for European countries\n",
        "norway_counties = alt.topo_feature('https://dmws.hkvservices.nl/dataportal/data.asmx/read?database=vega&key=europe', 'europe')\n",
        "\n",
        "# Create a base map of Norway using the geojson data.\n",
        "norway = alt.Chart(norway_counties).mark_geoshape(stroke=\"black\", fill=\"lightgrey\").encode(\n",
        ").project(\n",
        "    type='mercator',\n",
        "    scale=1000,\n",
        "    center=[16, 65],\n",
        ").properties(\n",
        "    width=600,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "# Create a map of wind farms using 'portfolio_data' with circles representing wind turbines. Geografic clusters are marked in different colors.\n",
        "south_west = alt.Chart(portfolio_data.loc[portfolio_data['Geografic_area'] =='South_west']).mark_circle(size=30, stroke=\"blue\", fill=\"blue\").encode(\n",
        "    longitude='Longitude:Q',\n",
        "    latitude='Latitude:Q',\n",
        ").project(\n",
        "    type='mercator',\n",
        "    scale=1000,\n",
        "    center=[16, 65],\n",
        ").properties(\n",
        "    width=600,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "mid = alt.Chart(portfolio_data.loc[portfolio_data['Geografic_area'] =='Mid']).mark_circle(size=30, stroke=\"red\", fill=\"red\").encode(\n",
        "    longitude='Longitude:Q',\n",
        "    latitude='Latitude:Q',\n",
        ").project(\n",
        "    type='mercator',\n",
        "    scale=1000,\n",
        "    center=[16, 65],\n",
        ").properties(\n",
        "    width=600,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "north = alt.Chart(portfolio_data.loc[portfolio_data['Geografic_area'] =='North']).mark_circle(size=30, stroke=\"green\", fill=\"green\").encode(\n",
        "    longitude='Longitude:Q',\n",
        "    latitude='Latitude:Q',\n",
        ").project(\n",
        "    type='mercator',\n",
        "    scale=1000,\n",
        "    center=[16, 65],\n",
        ").properties(\n",
        "    width=600,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "\n",
        "# Combine the maps by adding them together\n",
        "norway + south_west +mid + north\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55s18s_ERIXy"
      },
      "outputs": [],
      "source": [
        "#Running one wind farm\n",
        "def run_one_windfarm(selected_windfarm, power_curve = None, regression_curve = None):\n",
        "\n",
        "  #Choose the windfarm we want to analyze\n",
        "  Vindpark_navn = selected_windfarm\n",
        "  file_wind_farm = chosen_windfarm[Vindpark_navn]\n",
        "  Vindpark= portfolio[Vindpark_navn]\n",
        "  Vindpark_start_dato = Vindpark[\"Idriftsatt\"]\n",
        "\n",
        "\n",
        "  #Combine all the data into one file\n",
        "  combine_nc_dataset(file_wind_farm)\n",
        "\n",
        "  #Opening weather file\n",
        "  ds = xr.open_dataset(file_wind_farm +'_combined.nc')\n",
        "\n",
        "  #Import production data\n",
        "  if Vindpark_navn == 'Sandøy':\n",
        "    production_data = pd.read_csv('nve_prod_chosen.csv')\n",
        "    production_data.set_index('time',inplace=True)\n",
        "  else:\n",
        "    production_data = pd.read_csv('nve_prod_chosen_2023.csv')\n",
        "    production_data.set_index('time',inplace=True)\n",
        "\n",
        "\n",
        "  #Creating columns from imported weather data\n",
        "  u10 = construct_columns('u100',ds)\n",
        "  v10 = construct_columns('v100',ds)\n",
        "  fg10 = construct_columns('i10fg',ds)\n",
        "  t2m = construct_columns('t2m', ds)\n",
        "  fsr = construct_columns('fsr',ds)\n",
        "  sp = construct_columns('sp',ds)\n",
        "\n",
        "  columns = [u10,v10,fg10,t2m, fsr, sp]\n",
        "\n",
        "  #Creating distance dataframe\n",
        "  df_distance = get_df_distance(ds, Vindpark_navn)\n",
        "\n",
        "  #Creating direction\n",
        "  direction = create_wind_direction_df(v10, u10)\n",
        "\n",
        "  #Finding first production hour and the same hour one year later. The latter is the selected startpoint\n",
        "  _ , one_year = first_valid_hour(production_data[Vindpark_navn])\n",
        "  direction = direction[one_year:]\n",
        "  #Create weather dataframe\n",
        "\n",
        "  #Constructing weatherdata dataframe\n",
        "  weather_data = construct_weather_data(u10, v10,t2m, sp,fsr)\n",
        "\n",
        "  #Selecting productiondata for one wind farm\n",
        "  energy_prod = production_data[[Vindpark_navn]]\n",
        "\n",
        "  #Creating a dataframe with valid productionhours\n",
        "  start_hour, one_year = first_valid_hour(energy_prod)\n",
        "\n",
        "  #Selecting relevant parts of the data\n",
        "  valid_energy_prod = energy_prod[one_year:]\n",
        "  valid_energy_prod.index = pd.to_datetime(valid_energy_prod.index)\n",
        "\n",
        "  fg10.rename({'value': 'fg10'}, axis=1, inplace=True)\n",
        "\n",
        "  #Creating a common dataframe with weather and producction data among otther data\n",
        "  valid_weather_data = weather_data[one_year:]\n",
        "  wind=pd.DataFrame()\n",
        "  wind=pd.concat([valid_weather_data,valid_energy_prod, direction, fg10], axis=1)\n",
        "  wind.dropna(inplace=True)\n",
        "\n",
        "  #Creating a windrose showing wind direction\n",
        "  create_windrose(wind)\n",
        "\n",
        "  #Calculating cumulative maximum effect\n",
        "  df_cumulative_effect =  cumulative_effect_wind_farm(Vindpark)\n",
        "\n",
        "  #Finding rows considered downtime\n",
        "  df_weather_downtime = wind[['wind_speed', Vindpark_navn]]\n",
        "  df_downtime_zero_production = downtime(df_weather_downtime, Vindpark_navn)\n",
        "\n",
        "  #Making a dataframe suitable to windpowerlib\n",
        "  df_weather_windpowerlib = construct_weather_windpowerlib(valid_weather_data)\n",
        "\n",
        "  #remove zero entries\n",
        "  df_weather_windpowerlib_without_zero_downtime = remove_downtime_points(df_weather_windpowerlib, df_downtime_zero_production)\n",
        "  df_valid_prod_without_zero_downtime = remove_downtime_points(valid_energy_prod, df_downtime_zero_production)\n",
        "\n",
        "  #Simulating data\n",
        "  simulated_data, my_turbine = windpowerlib_simulation(Vindpark,Vindpark_navn, df_weather_windpowerlib)\n",
        "  plot_power_and_coeffcient_curve(my_turbine)\n",
        "\n",
        "  #Creating a dataframe with differnt data statistics and checking for irregularties in the data\n",
        "  df_data_statistics = pd.DataFrame({'Observasjoner tot prod': production_data[Vindpark_navn].shape[0],\n",
        "                                    'Observasjoner valid prod':valid_energy_prod.shape[0] ,\n",
        "                                    'Missing values prod':valid_energy_prod.isnull().sum(),\n",
        "                                    'Negative values prod':(valid_energy_prod < 0).values.sum(),\n",
        "                                    'Zero values prod':(valid_energy_prod == 0).values.sum(),\n",
        "                                    'Prod over capacity':(valid_energy_prod >Vindpark['Maksimal effekt']).sum(),\n",
        "                                    'Observasjoner df_windpowerlib':df_weather_windpowerlib.shape[0] ,\n",
        "                                    'Missing values wind_peed':df_weather_windpowerlib['wind_speed'].isnull().sum(),\n",
        "                                    'Missing values temperature':df_weather_windpowerlib['temperature'].isnull().sum(),\n",
        "                                     'Missing values pressure':df_weather_windpowerlib['pressure'].isnull().sum(),\n",
        "                                     'Missing values roughness_length':df_weather_windpowerlib['roughness_length'].isnull().sum(),\n",
        "                                    'Observasjoner sim':simulated_data.shape[0],\n",
        "                                    'Zero values sim':(simulated_data == 0).values.sum()}, index = [Vindpark_navn])\n",
        "  #Cleaning data\n",
        "  valid_energy_prod = data_cleaning(valid_energy_prod, Vindpark_navn, Vindpark)\n",
        "\n",
        "  #Creating a dataframe containing average termperature and and wind speed\n",
        "  df_avg_climate = pd.DataFrame({'Avg_Temperature':wind['temperature'].mean() ,\n",
        "                                  'Avg_wind_speed': wind['wind_speed'].mean() }, index = [Vindpark_navn])\n",
        "\n",
        "  #Identifying and creating a plot of partial downtime near effect lines\n",
        "  power_curve_wind_farm = windfarm_powercurve(my_turbine, Vindpark)\n",
        "  new_power_curve = create_80_power_curve(power_curve_wind_farm)\n",
        "  df_under_pc = find_points_under_powercurve(df_weather_downtime, new_power_curve, Vindpark_navn)\n",
        "\n",
        "  #Finding downtime near cumulative effect-lines\n",
        "  df_neigbours = find_neigbour_points(df_cumulative_effect,df_under_pc)\n",
        "\n",
        "  #Concatinating downtime into a final dataframe called df_downtime\n",
        "  df_downtime_neigbors = pd.DataFrame(df_neigbours[['wind_speed']])\n",
        "  df_downtime_windfarm = pd.concat([pd.DataFrame(df_downtime_zero_production['wind_speed']),df_downtime_neigbors])\n",
        "  df_downtime = pd.DataFrame(index=pd.to_datetime(production_data.index), columns = ['wind_speed'])\n",
        "  df_downtime = pd.concat([df_downtime, pd.DataFrame(df_downtime_zero_production['wind_speed']),df_downtime_neigbors])\n",
        "  df_downtime.rename(columns={\"wind_speed\": Vindpark_navn}, inplace=True)\n",
        "\n",
        "  #Calculating annual downtime in percent for one wind farm\n",
        "  df_annual_downtime_percent = ((df_downtime.notnull().astype('int').resample('A').sum()/valid_energy_prod.resample('A').count())*100)\n",
        "\n",
        "  #Remocing downtime for climate data and production data\n",
        "  df_weather_windpowerlib_without_downtime = remove_downtime_points(df_weather_windpowerlib_without_zero_downtime, df_neigbours)\n",
        "  df_valid_prod_without_downtime = remove_downtime_points(df_valid_prod_without_zero_downtime, df_neigbours)\n",
        "\n",
        "  #df_production_cleaned = valid_energy_prod\n",
        "  #df_production_cleaned['wind_speed'] = wind['wind_speed'][df_production_cleaned.index]\n",
        "\n",
        "  #Simulating using data without downtime.\n",
        "  simulated_data_without_downtime,_ = windpowerlib_simulation(Vindpark,Vindpark_navn, df_weather_windpowerlib_without_downtime)\n",
        "  #plot_production_powercurve(Vindpark_navn,df_production_cleaned,df_under_pc,df_neigbours,df_cumulative_effect,power_curve_wind_farm,new_power_curve)\n",
        "\n",
        "\n",
        "  #Running the regression models\n",
        "  df_results_lifetime, lr_metrics_lf, ran_metrics_lf, arima_metrics_lf, lr_residuals_lf,ran_residuals_lf = methods_regression(simulated_data,valid_energy_prod,Vindpark_navn, 'Month')\n",
        "  df_results_lr_season,df_results_ran_season, lr_metrics_s, ran_metrics_s = methods_regression(simulated_data,valid_energy_prod,Vindpark_navn, 'Season')\n",
        "  df_results_lifetime_downtime,lr_metrics_lf_d, ran_metrics_lf_d,arima_metrics_d, lr_residuals_lf_d,ran_residuals_lf_d = methods_regression(simulated_data_without_downtime,df_valid_prod_without_downtime, Vindpark_navn, 'Month')\n",
        "  df_results_lr_season_downtime,df_results_ran_season_downtime, lr_metrics_s_d, ran_metrics_s_d = methods_regression(simulated_data_without_downtime,df_valid_prod_without_downtime,Vindpark_navn, 'Season')\n",
        "  df_results_n_years, lr_metrics_y, ran_metrics_y,arima_metrics_y, lr_residuals_y,ran_residuals_y = methods_regression(simulated_data,valid_energy_prod,Vindpark_navn,'Month', 5)\n",
        "  print(df_results_lr_season)\n",
        "  return df_results_lifetime ,df_results_lr_season,df_results_ran_season,df_results_lifetime_downtime,df_results_lr_season_downtime,df_results_ran_season_downtime, df_results_n_years,df_data_statistics, df_downtime,df_annual_downtime_percent, df_distance, lr_metrics_lf, ran_metrics_lf, lr_residuals_lf,ran_residuals_lf, lr_metrics_s, ran_metrics_s, arima_metrics_lf,arima_metrics_d,arima_metrics_y, df_avg_climate\n",
        "\n",
        "df_results_lifetime ,df_results_lr_season,df_results_ran_season,df_results_lifetime_downtime,df_results_lr_season_downtime,df_results_ran_season_downtime, df_results_n_years,df_data_statistics, df_downtime,df_annual_downtime_percent, df_distance, lr_metrics_lf, ran_metrics_lf, lr_residuals_lf,ran_residuals_lf, lr_metrics_s, ran_metrics_s, arima_metrics_lf,arima_metrics_d,arima_metrics_y, df_avg_climate = run_one_windfarm('Sandøy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEOFBxCjzJLN",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Running all wind farms and storing results in separate dataframes\n",
        "def run_multiple_windfarms(chosen_windfarm):\n",
        "  #Creating all dataframes that are used to store results from the indicidual wind farms\n",
        "  df_results = pd.DataFrame()\n",
        "  df_results_downtime = pd.DataFrame()\n",
        "\n",
        "  df_data_statistics = pd.DataFrame()\n",
        "  df_results_n_years = pd.DataFrame()\n",
        "  df_distance = pd.DataFrame()\n",
        "\n",
        "  df_results_without_downtime = pd.DataFrame()\n",
        "  df_results_lr_season_without_downtime = pd.DataFrame()\n",
        "  df_results_ran_season_without_downtime = pd.DataFrame()\n",
        "\n",
        "  df_results_season_lr = pd.DataFrame()\n",
        "  df_results_season_ran = pd.DataFrame()\n",
        "\n",
        "  df_lr_metrics_lf = pd.DataFrame()\n",
        "  df_ran_metrics_lf = pd.DataFrame()\n",
        "\n",
        "  df_lr_metrics_s = pd.DataFrame()\n",
        "  df_ran_metrics_s = pd.DataFrame()\n",
        "\n",
        "  df_arima_metrics_lf = pd.DataFrame()\n",
        "  df_arima_metrics_s = pd.DataFrame()\n",
        "  df_arima_metrics_y = pd.DataFrame()\n",
        "\n",
        "  df_lr_residuals_lf = pd.DataFrame()\n",
        "  df_ran_residuals_ran = pd.DataFrame()\n",
        "\n",
        "  df_downtime = pd.DataFrame()\n",
        "  df_downtime_percent = pd.DataFrame()\n",
        "\n",
        "  df_avg_climate = pd.DataFrame()\n",
        "  #Running on wind farm at the time. All results are stored in different dataframes\n",
        "  for windfarm in chosen_windfarm:\n",
        "    print('##################' + windfarm + '###################')\n",
        "    results_lifetime,results_lr_season,results_ran_season,results_lifetime_without_downtime,results_lr_season_downtime,results_ran_season_downtime, results_n_years,data_statistics,downtime,annual_downtime_percent, distance, lf_metrics_lf, ran_metrics_lf, lr_residuals_lf,ran_residuals_lf, lr_metrics_s, ran_metrics_s,arima_metrics_lf,arima_metrics_d,arima_metrics_y,avg_climate = run_one_windfarm(windfarm)\n",
        "    print(results_lr_season,results_ran_season)\n",
        "    df_results = pd.concat([df_results,results_lifetime])\n",
        "    df_results_season_lr = pd.concat([df_results_season_lr, results_lr_season])\n",
        "    df_results_season_ran = pd.concat([df_results_season_ran, results_ran_season])\n",
        "\n",
        "    df_data_statistics = pd.concat([df_data_statistics,data_statistics])\n",
        "    df_results_without_downtime = pd.concat([df_results_without_downtime,results_lifetime_without_downtime])\n",
        "    df_results_lr_season_without_downtime = pd.concat([df_results_lr_season_without_downtime, results_lr_season_downtime])\n",
        "    df_results_ran_season_without_downtime = pd.concat([df_results_ran_season_without_downtime, results_ran_season_downtime])\n",
        "\n",
        "    df_results_n_years = pd.concat([df_results_n_years, results_n_years])\n",
        "    df_lr_metrics_lf = pd.concat([df_lr_metrics_lf, lf_metrics_lf])\n",
        "    df_ran_metrics_lf = pd.concat([df_ran_metrics_lf, ran_metrics_lf])\n",
        "\n",
        "    df_lr_metrics_s = pd.concat([df_lr_metrics_s, lr_metrics_s])\n",
        "    df_ran_metrics_s = pd.concat([df_ran_metrics_s, ran_metrics_s])\n",
        "\n",
        "    df_arima_metrics_lf = pd.concat([df_arima_metrics_lf, arima_metrics_lf])\n",
        "    df_arima_metrics_s = pd.concat([df_arima_metrics_s, arima_metrics_d])\n",
        "    df_arima_metrics_y = pd.concat([df_arima_metrics_y, arima_metrics_y])\n",
        "\n",
        "    df_lr_residuals_lf = pd.concat([df_lr_residuals_lf, lr_residuals_lf])\n",
        "    df_ran_residuals_ran = pd.concat([df_ran_residuals_ran, ran_residuals_lf])\n",
        "\n",
        "    df_distance = pd.concat([df_distance,distance])\n",
        "    df_downtime = pd.concat([df_downtime, downtime])\n",
        "    df_downtime_percent = pd.concat([df_downtime_percent, annual_downtime_percent], axis = 1)\n",
        "\n",
        "    df_avg_climate = pd.concat([df_avg_climate,avg_climate])\n",
        "\n",
        "  return df_results,df_results_n_years,df_results_season_lr,df_results_season_ran,df_results_without_downtime,df_results_lr_season_without_downtime,df_results_ran_season_without_downtime, df_downtime,df_downtime_percent,df_data_statistics, df_distance, df_lr_metrics_lf,df_ran_metrics_lf,df_lr_residuals_lf,df_ran_residuals_ran,df_lr_metrics_s,df_ran_metrics_s, df_arima_metrics_lf,df_arima_metrics_s, df_arima_metrics_y, df_avg_climate\n",
        "#List containg the chosen wind farms\n",
        "chosen = ['Egersund','Fakken','Hamnefjell','Hitra','Kjøllefjord','Lista','Raggovidda','Rye Vind','Røyrmyra','Sandøy','Skomakerfjellet','Tellenes','Valsneset','Ytre Vikna','Åsen II']\n",
        "\n",
        "#Running the function above\n",
        "results, results_n_years,results_season_lr,results_season_ran,results_without_downtime,results_lr_season_without_downtime,results_ran_season_without_downtime,df_downtime,df_downtime_percent,df_data_statistics, distance, lr_metrics_lf, ran_metrics_lf,lr_residuals_lf,ran_residuals_ran,lr_metrics_s,ran_metrics_s,df_arima_metrics_lf,df_arima_metrics_s, df_arima_metrics_y, df_avg_climate = run_multiple_windfarms(chosen)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General results\n",
        "\n",
        "Only selected models are outputted in this section. However, it is possible to retrived results from the following models: \\\n",
        "\n",
        "-results: general results  from all models using all data \\\n",
        "-results_n_years: results from all models using the first 5 years\\\n",
        "-results_season_lr: seasonal results from a linear regresson\\\n",
        "-results_season_ran: seasonal results from a RANSAC regresson\\\n",
        "-results_without_downtime results from all model using data without partial downtime \\\n",
        "-results_lr_season_without_downtime: seasonal results from linear model using data without downtime\\\n",
        "-results_ran_season_without_downtime: seasonal results from RANSAC model using data without downtime"
      ],
      "metadata": {
        "id": "Hv1t3Bwqzs0v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wiolaaa3bbj_"
      },
      "outputs": [],
      "source": [
        "#Dataframe of the general results\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average and weighted average from the models are then calculated."
      ],
      "metadata": {
        "id": "-Txioeg8LEZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results_avg, df_weighted = make_weighted_degradation(results)\n",
        "df_results_avg"
      ],
      "metadata": {
        "id": "EVoNAqlr848m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plotting of degradation rates"
      ],
      "metadata": {
        "id": "fc8r6xcP0zen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8zYETurd9v0"
      },
      "outputs": [],
      "source": [
        "#Making a DataFrame consisting of geografic-labels and age-labels\n",
        "df_cluster = pd.DataFrame(index = results.index)\n",
        "df_cluster['Geografic'] = portfolio_data['Geografic_area']\n",
        "df_cluster['Age_groups'] = portfolio_data['Age_groups']\n",
        "df_cluster\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2tKia3EqSJr"
      },
      "outputs": [],
      "source": [
        "#Adding a geografic label to the main result dataframe and weighted result dataframe\n",
        "results['Geografic'] = df_cluster['Geografic']\n",
        "df_weighted['Geografic'] = df_cluster['Geografic']\n",
        "\n",
        "#Plotting the result of the individual linear regression model to the wind farms\n",
        "linear_chart = alt.Chart(results.reset_index()).mark_bar(opacity = 0.7).encode(\n",
        "    x= alt.X('Wind_farm:O',title='Wind farm'),\n",
        "    y= alt.Y('Linear_degradation:Q',title='Yearly degradation [%]'),\n",
        "    color = 'Geografic:O',\n",
        ").properties(\n",
        "    title='Annual degradation using Linear Regression'\n",
        ")\n",
        "linear_weighted_chart = alt.Chart(df_weighted.reset_index()).mark_bar(opacity = 0.7).encode(\n",
        "    x=alt.X('Wind_farm:O',title='Wind farm'),\n",
        "    y=alt.Y('Weighted_Linear_degradation:Q',title='[Degradation * proportion]'),\n",
        "    color = alt.Color('Geografic', scale=alt.Scale(domain = ['South_west', 'Mid', 'North'], range=['blue', 'red', 'green']))\n",
        ").properties(\n",
        "    title='Weighted annual degradation using Linear Regression'\n",
        ")\n",
        "\n",
        "display(alt.hconcat(linear_chart, linear_weighted_chart).configure_axis(\n",
        "    labelFontSize=15,\n",
        "    titleFontSize=20))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the result of the individual RANSAC regression model to the wind farms\n",
        "\n",
        "ransac_chart = alt.Chart(results.reset_index()).mark_bar(opacity = 0.7).encode(\n",
        "    x= alt.X('Wind_farm:O',title='Wind farm'),\n",
        "    y= alt.Y('Ransac_degradation:Q',title='Yearly degradation [%]'),\n",
        "    color = 'Geografic:O'\n",
        ").properties(\n",
        "    title='Annual degradation using RANSAC Regression'\n",
        ")\n",
        "ransac_weighted_chart = alt.Chart(df_weighted.reset_index()).mark_bar(opacity = 0.7).encode(\n",
        "    x=alt.X('Wind_farm:O',title='Wind farm'),\n",
        "    y=alt.Y('Weighted_Ransac_degradation:Q',title='[Degradation * proportion]'),\n",
        "    color = alt.Color('Geografic', scale=alt.Scale(domain = ['South_west', 'Mid', 'North'], range=['blue', 'red', 'green']))\n",
        ").properties(\n",
        "    title='Weighted annual degradation using Ransac Regression'\n",
        ")\n",
        "\n",
        "display(alt.hconcat(ransac_chart, ransac_weighted_chart).configure_axis(\n",
        "    labelFontSize=15,\n",
        "    titleFontSize=20))"
      ],
      "metadata": {
        "id": "Z4su1tQaTx_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histograms showing distributions of degradation rates"
      ],
      "metadata": {
        "id": "kuK_qh2-zyRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting histograms showing the distrubution of estimated degradation rates. One plot contains all three models and the other contains only Linear and RANSAC regression."
      ],
      "metadata": {
        "id": "EK9UU8CDL6UO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTOPH8hC7Vl-"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure()\n",
        "plt.hist([results['Linear_degradation'],results['Ransac_degradation'],results['Arima degradation']], bins=30, histtype='bar', label = ['Linear', 'Ransac', 'Arima'])\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('Yearly Degradation')\n",
        "plt.ylabel('Numbers of Wind farms [%]')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daUlg0eS9uEt"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure()\n",
        "plt.hist([results['Linear_degradation'],results['Ransac_degradation']], bins=30, histtype='bar', label = ['Linear', 'Ransac'])\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('Yearly Degradation [%]')\n",
        "plt.ylabel('Numbers of Wind farms')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results without partial downtime\n",
        "\n",
        "Results without partial downtime using all data.\n"
      ],
      "metadata": {
        "id": "SQbxy8k0z5_c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ace49hHr1dCw"
      },
      "outputs": [],
      "source": [
        "results_without_downtime.set_index('Wind_farm', inplace=True)\n",
        "results_without_downtime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average and weighted average from the models are then calculated."
      ],
      "metadata": {
        "id": "yMg2c1KyLBvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results_avg, df_weighted = make_weighted_degradation(results_without_downtime)\n",
        "df_results_avg"
      ],
      "metadata": {
        "id": "enZSH4Rg80ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results from the first five production years\n",
        "\n",
        "Outputting the result from the first five years of production."
      ],
      "metadata": {
        "id": "AS14UPA-z99K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9Cany7cj1C2"
      },
      "outputs": [],
      "source": [
        "results_n_years.set_index('Wind_farm',inplace=True)\n",
        "results_n_years"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average and weighted average from the models are then calculated."
      ],
      "metadata": {
        "id": "Acb-mPi3K13v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXoxkodo5je8"
      },
      "outputs": [],
      "source": [
        "df_results_avg, df_weighted = make_weighted_degradation(results_n_years)\n",
        "df_results_avg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results from the regression of seasonal data.\n",
        "\n"
      ],
      "metadata": {
        "id": "PD_4YUZ_1lIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAo1IrvlUHf0"
      },
      "outputs": [],
      "source": [
        "results_season_lr.set_index('Wind_farm', inplace=True)\n",
        "results_season_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ-6_zX6caJE"
      },
      "outputs": [],
      "source": [
        "results_season_ran.set_index('Wind_farm', inplace=True)\n",
        "results_season_ran"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go_YSfNC-Kib"
      },
      "outputs": [],
      "source": [
        "results_lr_season_without_downtime.set_index('Wind_farm', inplace=True)\n",
        "results_lr_season_without_downtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppe9zSGv-iMq"
      },
      "outputs": [],
      "source": [
        "results_ran_season_without_downtime.set_index('Wind_farm', inplace=True)\n",
        "results_ran_season_without_downtime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final result\n",
        "\n",
        "In this section, the final result with confidence interval are calculated."
      ],
      "metadata": {
        "id": "DQZSsCWA0ktT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBOrT9qfZxRU"
      },
      "outputs": [],
      "source": [
        "avg_result_linear = 0.5* df_results_avg['Ransac Reg Mean'] + 0.5 * df_results_avg['Ransac Reg Weighted Avg']\n",
        "avg_result_linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFi_Xl2Ua7Ww"
      },
      "outputs": [],
      "source": [
        "\n",
        "interval = mean_confidence_interval(results_without_downtime['Ransac_degradation'],df_weighted['Weighted_Ransac_degradation'])\n",
        "print(interval)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimated downtime\n",
        "\n",
        "In this section he development of downtime are estimated and different plots of downtime are made."
      ],
      "metadata": {
        "id": "-P8ewaPCy2uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#All hours that are considered downtime are marked as 1 and the rest of data points are marked 0\n",
        "newdf = df_downtime.notnull().astype('int')\n",
        "newdf"
      ],
      "metadata": {
        "id": "SD_WDwVdpdx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFXfaeef6EG_"
      },
      "outputs": [],
      "source": [
        "#Finding total annual hours of downtime for each wind farm\n",
        "_, one_year = first_valid_hour(newdf, 'Sandøy')\n",
        "df_monthly = newdf[one_year:].resample('A').sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quzYuUYwdZov"
      },
      "outputs": [],
      "source": [
        "#plotting annual partial downtime for individual wind farms\n",
        "df_monthly.plot()\n",
        "plt.xlabel('Years')\n",
        "plt.ylabel('Numbers of downtime hours')\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(1.2, 0.95))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Estimated annual partial downtime in percent\n",
        "df_downtime_percent"
      ],
      "metadata": {
        "id": "G7uzPvjgNl_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding total annual partial downtime for all wind farms\n",
        "final_avg = pd.DataFrame(df_downtime_percent.sum(axis=1), columns=['Avg_Degrad_percent'])\n",
        "final_avg['hrs_count'] = df_downtime_percent.count(axis=1)\n",
        "final_avg['Annual_degrad'] = final_avg['Avg_Degrad_percent']/final_avg['hrs_count']\n",
        "final_avg.fillna(0, inplace = True)\n",
        "final_avg"
      ],
      "metadata": {
        "id": "lvefg0CFU30i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ujTddH2dMye"
      },
      "outputs": [],
      "source": [
        "# Creating a simple linear regression to find the slope of the partial downtime\n",
        "final_avg['Time'] = np.arange(len(final_avg.index))\n",
        "X = final_avg.loc[:, ['Time']].values  # features\n",
        "y = final_avg.loc[:, ['Annual_degrad']].values  # target\n",
        "\n",
        "lr = LinearRegression().fit(X,y)\n",
        "print(f'Annual change in degradation: {float(lr.coef_)} pp/y')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting annual downtime and regression line\n",
        "plt.figure()\n",
        "plt.scatter(final_avg['Time'], final_avg['Annual_degrad'])\n",
        "plt.plot(final_avg['Time'], float(lr.intercept_)+ float(lr.coef_) * final_avg['Time'], 'b')\n",
        "plt.xlabel('Years')\n",
        "plt.ylabel('Degradation [%]')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y-yvalJUWbR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data statistics and diagnostics"
      ],
      "metadata": {
        "id": "57NLmrJ8zJGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data statistics and diagnostic\n",
        "df_data_statistics"
      ],
      "metadata": {
        "id": "KZPgexJIEDxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Outputting some statistics of data\n",
        "\n",
        "print('Number of valid observations:', df_data_statistics['Observasjoner valid prod'].sum())\n",
        "print('Number of zero values:', df_data_statistics['Zero values prod'].sum())\n",
        "print('Number of production over capacity:', df_data_statistics['Prod over capacity'].sum())\n",
        "\n",
        "print('Percent zero values:', (df_data_statistics['Zero values prod'].sum()/df_data_statistics['Observasjoner valid prod'].sum())*100)\n",
        "print('Percent of over capacity values:', (df_data_statistics['Prod over capacity'].sum()/df_data_statistics['Observasjoner valid prod'].sum())*100)\n",
        "print('Percent of missing values:', (df_data_statistics['Missing values prod'].sum()/df_data_statistics['Observasjoner valid prod'].sum())*100)\n",
        "print('Percent of negative values:', (df_data_statistics['Negative values prod'].sum()/df_data_statistics['Observasjoner valid prod'].sum())*100)\n"
      ],
      "metadata": {
        "id": "YhCWMrDP4pDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results metrics\n",
        "\n",
        "This section contain metrics to the different models. Only metrics to the three main models are outputted now. Metrics for these models are estimated and can be retrieved:\n",
        "\n",
        "\n",
        "\n",
        "lr_metrics_lf:  linear model of all data\n",
        "ran_metrics_lf:  RANSAC model of all data\n",
        "lr_metrics_s: linear model of seasonal data\n",
        "ran_metrics_s: RANSAC model of seasonal data\n",
        "df_arima_metrics_lf: ARIMA model of all data\n",
        "df_arima_metrics_s:ARIMA model of seasonal data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RB0KdEPhzf8z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5cVuVtVDF63"
      },
      "outputs": [],
      "source": [
        "lr_metrics_lf.set_index('Wind Farm', inplace = True)\n",
        "lr_metrics_lf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5xW35IXDUX2"
      },
      "outputs": [],
      "source": [
        "ran_metrics_lf.set_index('Wind Farm', inplace = True)\n",
        "ran_metrics_lf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results statistical tests\n",
        "\n",
        "Statistical test for the linear model and RANSAC model are outputted."
      ],
      "metadata": {
        "id": "UdDjTN9Yzmux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7dHIj0uDeN0"
      },
      "outputs": [],
      "source": [
        "lr_residuals_lf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFsUu8QYDggJ"
      },
      "outputs": [],
      "source": [
        "ran_residuals_ran"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt2rYXJGWHpD"
      },
      "outputs": [],
      "source": [
        "df_old_turbines = results_n_years.loc[portfolio_data['Age_groups'] == 'Old_turbine']\n",
        "df_new_turbines = results_n_years.loc[portfolio_data['Age_groups'] == 'New_turbine']\n",
        "\n",
        "df_south_west = results.loc[portfolio_data['Geografic_area'] == 'South_west']\n",
        "df_mid = results.loc[portfolio_data['Geografic_area'] == 'Mid']\n",
        "df_north = results.loc[portfolio_data['Geografic_area'] == 'North']\n",
        "\n",
        "group = [df_old_turbines,df_new_turbines,df_south_west,df_mid,df_north]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sw_avg_climate = df_avg_climate.loc[portfolio_data['Geografic_area'] == 'South_west']\n",
        "df_sw_avg_climate"
      ],
      "metadata": {
        "id": "KbgGCykpLbhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Avg_Temperature, south_west norway',df_sw_avg_climate['Avg_Temperature'].mean()-273.15)\n",
        "print('Avg_wind_speed, south_west norway',df_sw_avg_climate['Avg_wind_speed'].mean())"
      ],
      "metadata": {
        "id": "BmKAdy8tL1Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mid_avg_climate = df_avg_climate.loc[portfolio_data['Geografic_area'] == 'Mid']\n",
        "df_mid_avg_climate"
      ],
      "metadata": {
        "id": "vKbSjufBLvKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Avg_Temperature, mid norway',df_mid_avg_climate['Avg_Temperature'].mean()-273.15)\n",
        "print('Avg_wind_speed, mid norway',df_mid_avg_climate['Avg_wind_speed'].mean())"
      ],
      "metadata": {
        "id": "Z-l0miVvTfLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_north_avg_climate = df_avg_climate.loc[portfolio_data['Geografic_area'] == 'North']\n",
        "df_north_avg_climate"
      ],
      "metadata": {
        "id": "6MQmjwCBLvrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Avg_Temperature, north norway',df_north_avg_climate['Avg_Temperature'].mean()-273.15)\n",
        "print('Avg_wind_speed, north norway',df_north_avg_climate['Avg_wind_speed'].mean())"
      ],
      "metadata": {
        "id": "q0Fg7UnDTk7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grouping of wind farms into different cases\n",
        "\n",
        "Wind farms are grouped into different locations and into newer and older turbines using DataFrames."
      ],
      "metadata": {
        "id": "tCy4rFDkJaJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_old_turbines"
      ],
      "metadata": {
        "id": "xRRKFbnoJWXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new_turbines"
      ],
      "metadata": {
        "id": "luAISrvNJYcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the g\n",
        "\n",
        "for group in [df_old_turbines,df_new_turbines,df_south_west,df_mid,df_north]:\n",
        "  print(group)"
      ],
      "metadata": {
        "id": "a1EUwYIzjKoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msoyOgA8QETt"
      },
      "outputs": [],
      "source": [
        "\n",
        "for location in [df_south_west,df_mid,df_north]:\n",
        "  df_results_avg, df_weighted = make_weighted_degradation(location)\n",
        "  print(df_results_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison cases\n",
        "\n",
        "In this sections, comparison groups are defined. These are grouped into larger groups by type of model and type of comparison case. The pre-defined groups are then compared using a Mannwhitney U-test. All the test are conducted by iterating over the pairs."
      ],
      "metadata": {
        "id": "FSrptr2U095-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fzFN9SRimoC"
      },
      "outputs": [],
      "source": [
        "#Defining different pairs of groups to compare using MannWhitney U-Test\n",
        "\n",
        "old_new_lr = {'Old': df_old_turbines['Linear_degradation'], 'New': df_new_turbines['Linear_degradation']}\n",
        "old_new_ran = {'Old': df_old_turbines['Ransac_degradation'], 'New': df_new_turbines['Ransac_degradation']}\n",
        "\n",
        "\n",
        "u_test_technology_lr = ('Linear Regression', [old_new_lr])\n",
        "u_test_technology_ran = ('Ransac Regression',[old_new_ran])\n",
        "\n",
        "#Defining groups based on geographics\n",
        "south_mid_lr = {'df_south_west':df_south_west['Linear_degradation'], 'df_mid': df_mid['Linear_degradation']}\n",
        "south_mid_ran = {'df_south_west': df_south_west['Ransac_degradation'], 'df_mid': df_mid['Ransac_degradation']}\n",
        "\n",
        "south_north_lr = {'df_south_west':df_south_west['Linear_degradation'], 'df_north': df_north['Linear_degradation']}\n",
        "south_north_ran = {'df_south_west': df_south_west['Ransac_degradation'], 'df_north': df_north['Ransac_degradation']}\n",
        "\n",
        "mid_north_lr = {'df_mid':df_mid['Linear_degradation'],'df_north': df_north['Linear_degradation']}\n",
        "mid_north_ran = {'df_mid': df_mid['Ransac_degradation'], 'df_north': df_north['Ransac_degradation']}\n",
        "\n",
        "\n",
        "u_test_geografic_lr = ('Linear Regression', [south_mid_lr,south_north_lr,mid_north_lr])\n",
        "u_test_geografic_ran = ('Ransac Regression',[south_mid_ran,south_north_ran,mid_north_ran])\n",
        "\n",
        "#Defining groups based on downtime and different life span\n",
        "results_resultsWODowntime_ran = {'results': results['Ransac_degradation'], 'results_without_downtime': results_without_downtime['Ransac_degradation']}\n",
        "results_resultsWODowntime_lr = {'results': results['Linear_degradation'], 'results_without_downtime': results_without_downtime['Linear_degradation']}\n",
        "\n",
        "results_results5_years_lr = {'results': results['Linear_degradation'], 'results_5_years': results_n_years['Linear_degradation']}\n",
        "results_results5_years_ran ={'results': results['Ransac_degradation'], 'results_5_years': results_n_years['Ransac_degradation']}\n",
        "\n",
        "\n",
        "u_test_results_lr = ('Linear_degradation', [results_resultsWODowntime_lr,results_results5_years_lr ])\n",
        "u_test_results_ran = ('Ransac_degradation',[results_resultsWODowntime_lr,results_results5_years_lr ])\n",
        "\n",
        "#Defining groups based on different seasons\n",
        "q1_q2_ran = {'Q1': results_season_ran['Q1'], 'Q2': results_season_ran['Q2']}\n",
        "q1_q3_ran = {'Q1': results_season_ran['Q1'], 'Q3': results_season_ran['Q3']}\n",
        "q1_q4_ran = {'Q1': results_season_ran['Q1'], 'Q4': results_season_ran['Q4']}\n",
        "q2_q3_ran = {'Q2': results_season_ran['Q2'], 'Q3': results_season_ran['Q3']}\n",
        "q2_q4_ran = {'Q2': results_season_ran['Q2'], 'Q4': results_season_ran['Q4']}\n",
        "q3_q4_ran = {'Q3': results_season_ran['Q3'], 'Q4': results_season_ran['Q4']}\n",
        "\n",
        "u_test_seasons_ran = ('Ransac Regression', [q1_q2_ran,q1_q3_ran,q1_q4_ran,q2_q3_ran,q2_q4_ran,q2_q4_ran,q3_q4_ran])\n",
        "\n",
        "q1_q2_lr = {'Q1': results_season_lr['Q1'], 'Q2': results_season_lr['Q2']}\n",
        "q1_q3_lr = {'Q1': results_season_lr['Q1'], 'Q3': results_season_lr['Q3']}\n",
        "q1_q4_lr = {'Q1': results_season_lr['Q1'], 'Q4': results_season_lr['Q4']}\n",
        "q2_q3_lr = {'Q2': results_season_lr['Q2'], 'Q3': results_season_lr['Q3']}\n",
        "q2_q4_lr = {'Q2': results_season_lr['Q2'], 'Q4': results_season_lr['Q4']}\n",
        "q3_q4_lr = {'Q3': results_season_lr['Q3'], 'Q4': results_season_lr['Q4']}\n",
        "\n",
        "u_test_seasons_lr = ('Linear Regression', [q1_q2_lr,q1_q3_lr,q1_q4_lr,q2_q3_lr,q2_q4_lr,q3_q4_lr])\n",
        "\n",
        "q1_q2_lr_d = {'Q1': results_lr_season_without_downtime['Q1'], 'Q2': results_lr_season_without_downtime['Q2']}\n",
        "q1_q3_lr_d = {'Q1': results_lr_season_without_downtime['Q1'], 'Q3': results_lr_season_without_downtime['Q3']}\n",
        "q1_q4_lr_d = {'Q1': results_lr_season_without_downtime['Q1'], 'Q4': results_lr_season_without_downtime['Q4']}\n",
        "q2_q3_lr_d = {'Q2': results_lr_season_without_downtime['Q2'], 'Q3': results_lr_season_without_downtime['Q3']}\n",
        "q2_q4_lr_d = {'Q2': results_lr_season_without_downtime['Q2'], 'Q4': results_lr_season_without_downtime['Q4']}\n",
        "q3_q4_lr_d = {'Q3': results_lr_season_without_downtime['Q3'], 'Q4': results_lr_season_without_downtime['Q4']}\n",
        "\n",
        "u_test_seasons_wdowntime_lr = ('Linear Regression', [q1_q2_lr_d,q1_q3_lr_d,q1_q4_lr_d,q2_q3_lr_d,q2_q4_lr_d,q3_q4_lr_d])\n",
        "\n",
        "q1_q2_ran_d = {'Q1': results_ran_season_without_downtime['Q1'], 'Q2': results_ran_season_without_downtime['Q2']}\n",
        "q1_q3_ran_d = {'Q1': results_ran_season_without_downtime['Q1'], 'Q3': results_ran_season_without_downtime['Q3']}\n",
        "q1_q4_ran_d = {'Q1': results_ran_season_without_downtime['Q1'], 'Q4': results_ran_season_without_downtime['Q4']}\n",
        "q2_q3_ran_d = {'Q2': results_ran_season_without_downtime['Q2'], 'Q3': results_ran_season_without_downtime['Q3']}\n",
        "q2_q4_ran_d = {'Q2': results_ran_season_without_downtime['Q2'], 'Q4': results_ran_season_without_downtime['Q4']}\n",
        "q3_q4_ran_d = {'Q3': results_ran_season_without_downtime['Q3'], 'Q4': results_ran_season_without_downtime['Q4']}\n",
        "\n",
        "u_test_seasons_wdowntime_ran = ('Linear Regression', [q1_q2_ran_d,q1_q3_ran_d,q1_q4_ran_d,q2_q3_ran_d,q2_q4_ran_d,q3_q4_ran_d])\n",
        "\n",
        "u_test_groups = [u_test_technology_lr,u_test_technology_ran,u_test_geografic_lr,u_test_geografic_ran,u_test_results_lr, u_test_results_ran,u_test_seasons_lr,u_test_seasons_ran,u_test_seasons_wdowntime_lr,u_test_seasons_wdowntime_ran]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toaTC4maMpGI"
      },
      "outputs": [],
      "source": [
        "#Running all testing pair using the for-loop.\n",
        "for test_group in u_test_groups:\n",
        "  print(run_u_test_case(test_group))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}